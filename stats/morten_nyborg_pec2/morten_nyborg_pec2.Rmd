---
title: "A2 - Analítica descriptiva e inferencial."
author: "Autor: Morten Nyborg"
date: "Noviembre 2021"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
  word_document: default
  pdf_document:
    highlight: zenburn
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
if(!require(nortest)){
    install.packages('nortest',repos='http://cran.es.r-project.org')
    require(nortest)
}
if(!require(MASS)){
    install.packages('MASS',repos='http://cran.es.r-project.org')
    require(MASS)
}
if(!require(ggplot2)){
    install.packages('ggplot2',repos='http://cran.es.r-project.org')
    require(ggplot2)
}
```


# Lectura del fichero y preparación de los datos  
  
Cargamos los datos con el comando read.csv y guardamos los datos como "claim". Para verificar los datos imprimimos los primer cinco filas y obtenemos las dimensiones del dataset. El dataset contiene **50526 filas y 17 columnas**.    
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Loading data.
claim <- read.csv("./train_clean2.csv", header = TRUE, stringsAsFactors = FALSE, sep = ",")
# Print 5 first rows.
head(claim)
# No rows and columns.
dim(claim)

```   

# Coste de los siniestros  


## Análisis visual
  
1. **Mostrad con un diagrama de caja la distribución de la variable ‘UltCost‘**  

Mostramos la distribución de la variable **UltCost** con un diagrama de caja.  

Los valores que toma la variable tienen un rango grande, existen outliers y casi no podemos ver la caja y la mediana dentro de la caja. El valor de la mediana se encuentra en la parte baja del rango de valores. 

Todos los valores que están fuera de cuartil 3 + 1.5 IQR o por debajo de el cuartil 1 - 1.5 IQR son considerados outliers. Podemos ver que una gran parte de los valores son outliers.  

```{r echo=TRUE, message=FALSE, warning=FALSE}

boxplot(claim$UltCost, main = "Box plot UltCost", col = "red")

```
  
2. **Transformad la variable ‘UltCost‘ a escala logarítmica y mostrad el diagrama de caja**  

Calculamos el UltCost en la escala logarítmica y guardomos los valores en la variable **Ultcost.log**. Entonces visualizamos la distribución de la variable **UltCost.log** con un diagrama de caja.  

Con respecto al diagrama de caja anterior podemos ver perfectamente la caja y la mediana. Hay pocos valores fuera de los quartiles 1 - 1.5IQR y 3+1.5IQR


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Calculate log of UltCost and save as variable.
Ultcost.log <- log(claim$UltCost)

# Make a box plot of the variable.
boxplot(Ultcost.log, main = "Box plot log UltCost LOG", col = "red")

```
  
3. **Interpretad los gráficos brevemente.**  

En el primer gráfico interpretamos que la variable UltCost sigue una distribución que tiene muchos valores en la parte baja del rango. Todos los outliers que vemos son valores outliers que en un histograma se verían como una cola larga a la derecha.  

Después de aplicar la escala logarítmica a la variable, conseguimos un diagrama de caja mucho más visible, la distribución de la variable parece más cercana a una normal, ya no hay tantos outliers. 




## Comprobación de normalidad  

**Realizad inspección visual de normalidad en base a los gráficos que consideréis oportunos**  

Realizamos un histograma y un qqplot para ver si la variable sigue una distribución normal. Un qqplot muestra el ajuste de una distribución a la distribución normal.   

Como hemos dicho antes, la mayoría de los valores de esta variable son bajos y hay una cola larga, casi no visible a la derecha. En el QQPlot también vemos que la variable no parece seguir una distribución normal.  

```{r echo=TRUE, message=FALSE, warning=FALSE}

truehist(claim$UltCost, main = 'Ultcost distribution', col = "orange")
qqnorm(claim$UltCost, main = 'UltCost', col = "blue");qqline(claim$UltCost)

```

**Realizad contraste de normalidad de Lilliefors**  

El test de Kolmogorov-Smirnov plantea la hipótesis nula de normalidad y la hipótesis alternativa de no normalidad. Tenemos un p value muy bajo, menor que 0.01 y esto permite que aceptemos $H_1$ por la que la variable no sigue una distribución normal.  

```{r echo=TRUE, message=FALSE, warning=FALSE}

lillie.test(claim$UltCost)

```


p < 0.05 = α => rechazamos la hipótesis nula


**Realizad inspección visual y contraste de normalidad a la variable UltCost en escala logarítmica**  

Hacemos lo mismo a escala logarítmica. El histograma es bastante simétrico y el QQPlot muestra que la distribución de la variable a escala logarítmica se ajusta bastante a la distribución normal teórica, salvo en los bordes del gráfico. Estos valores son los outliers que vimos en el diagrama de caja después de aplicar la transformación a escala logarítmica.  


```{r echo=TRUE, message=FALSE, warning=FALSE}
truehist(Ultcost.log, main = 'log Ultcost distribution', col = "orange")
qqnorm(Ultcost.log, main = 'log UltCost', col = "blue");qqline(Ultcost.log)


```

Volvemos a hacer el test de Kolmogorov-Smirnov y esta vez tenemos un p value que no nos permite rechazar $H_0$, por lo tanto, la variable a escala logarítmica sigue una distribución normal.  

p-value > 0.05 = $\alpha$ 


```{r echo=TRUE, message=FALSE, warning=FALSE}

lillie.test(Ultcost.log)

```



## Intervalo de confianza de la media poblacional de la variable UltCost  

**Calculad manualmente el intervalo de confianza al 95% de la media poblacional de la variable ‘UltCost‘ en escala original**  
  
Tenemos la varianza de la población desconocida y tenemos que usar el estadístico z.


  
```{r echo=TRUE, message=FALSE, warning=FALSE}
alpha <- 1-0.95
sd <- sd(claim$UltCost)
n <- nrow(claim)
SE <- sd / sqrt(n)
z <- qt(alpha/2, df=n-1, lower.tail = FALSE)
L <- mean(claim$UltCost) - z*SE
U <- mean(claim$UltCost) + z*SE
round(c(L,U), 2)


```
**¿Podemos asumir la hipótesis de normalidad para el cálculo del intervalo de confianza sobre la media muestral del coste en escala original? Argumentar la respuesta.**  

Podemos asumir que la media muestral de la población sigue una distribución normal incluso tomando una variable con una distribución tan pesada a la izquierda como la de la variable coste final siempre que la muestra sea mayor que 30 obsevaciones. Asumimos la normalidad por el Teorema del Límite Central. 


**A partir del resultado obtenido, explicad cómo se interpreta el intervalo de confianza**
 
Obtenemos el intervalo de confianza de 9938.86 - 10356.48. Esto significa que si hacemos un número de muestras infinito de la población, el 95% de los intervalos derivados de estas muestras incluirá la media poblacional. 


```{r echo=TRUE, message=FALSE, warning=FALSE}



```  


# Coste inicial y final de los siniestros  

## Justificación del test a aplicar  

Podemos hacer el contraste de una muestra. Aunque las variables coste final y coste inicial son diferentes, podemos calcular una variable que muestre la diferencia de costes. Es un contraste sobre la media ya que queremos ver si en promedio el coste estimado cubre el coste del siniestro. Es un test bilateral, con desviación poblacional desconocida así que tenemos que estimarla a partir de la desviación de la muestra. En este caso la variable de interés sigue una distribución t de student con n-1 grados de libertad.  Asumimos que la media muestral sigue una distribución normal ya que la muestra contiene más que 30 observaciones. Usaremos un test paramétrico.  




```{r echo=TRUE, message=FALSE, warning=FALSE}

DifCost <- claim$UltCost - claim$IniCost

```





## Escribid la hipótesis nula y la alternativa


Pregunta de investigación: ¿Podemos aceptar que no hay diferencias entre IniCost y UltCost?  

**$H_0$:** DifCost = 0  
**$H_1$:** DifCost $\neq$ 0

## Cálculos

Usamos un nivel de confianza de 95% => $\alpha$ = 0.05.  

Creamos un funcion para realizar el contraste de hipótesis.  
```{r echo=TRUE, message=FALSE, warning=FALSE}

my.ttest <- function(x,mu,alpha) {
  mean <- mean(x)
  sd <- sd(x)
  n <- length(x)
  tobs <- (mean-mu)/(sd/sqrt(n))
  # Range of acceptance.
  tcrit.L <- qt(alpha/2, df=n-1)
  tcrit.U <- qt(1-alpha/2, df=n-1)
  # Calculate the p-value
  pvalue <- pt(abs(tobs), lower.tail = FALSE, df=n-1)*2
  return(data.frame(tcrit.L, tcrit.U, tobs, pvalue))
}

```
  
Aplicamos la funcion que acabamos de crear.    
```{r echo=TRUE, message=FALSE, warning=FALSE}

my.ttest(DifCost, 0, 0.05)

``` 
## Conclusión   

El estadístico de contraste t observado se encuentra fuera del rango de aceptación de la hipótesis nula que afirma que de media el coste estimado cubre el coste del siniestro. Por otra parte, el valor pvalue es muy bajo y está por debajo del nivel de significancia $\alpha$ y esto significa que no estaríamos cometiendo un error importante si rechazamos $H_0$. 

Rechazamos $H_0$ con un nivel de confianza del 95%, sí hay diferencia entre el coste inicial y el coste final.


## Comprobación   


Comprobamos con el t.test que los cálculos que hemos hecho son correctos. El estadístico tobs coincide y pvalue en nuestro test propio es 2.2e-16, menor que 2.2e-16   

```{r echo=TRUE, message=FALSE, warning=FALSE}
t.test(DifCost, alternative = "two.sided", mu=0)


```



# Diferencia de salario según género  
  
**"Nos preguntamos si las mujeres reciben un menor salario"**

## Análisis visual  


Creamos las muestras  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Create new dfs for female and male.
wage.F <- claim$WeeklyWages[claim$Gender=="F"]
wage.M <- claim$WeeklyWages[claim$Gender=="M"]

```   
  


Visualizamos los datos de sueldos semanales de hombres y mujeres.  



```{r echo=TRUE, message=FALSE, warning=FALSE}
# Remove unknown before plot.
without.unknown<- claim[claim$Gender != 'U',]
boxplot(without.unknown$WeeklyWages~without.unknown$Gender, col="yellow", main= "Weekly wages by gender", log='y', xlab = "Gender", ylab = "Log Weekly Wages")

``` 




## Interpretación  
  
Visualmente podemos ver que las mujeres tienen una mediana de sueldo algo más baja, que Q1 es más bajo y también Q1-1.5IQR. Además de esto, no parece que haya diferencias muy grandes en el sueldo.  


    
## Escribid la hipótesis nula y la alternativa  
**¿Podemos aceptar que los hombres cobran más que las mujeres en promedio a la semana?**  
  
**$H_0$:** El salario medio a la semana de los hombres = el salario medio a la semana de las mujeres  
**$H_1$:** El salario medio a la semana de los hombres > el salario medio a la semana de las mujeres

## Justificación del test a aplicar  
  
* Tenemos **dos muestras independientes**: hombres y mujeres y realizamos un contraste de hipótesis de dos muestras.  
* Un contraste sobre la **media**.  
* Las **varianzas poblacionales** son **desconocidas**  
* **Test unilateral por la derecha.**  
* Según el Teorema del límite central asumimos la distribución normal de la media muestral (muestra mayor que 30)  
* Con todo lo dicho, aplicamos un Test paramétrico.  
* No sabemos si las varianzas muestrales son iguales o no, tendremos que hacer un **test de homoscedasticidad**.  

  

## Cálculos  



Hacemos un test de homoscedasticidad para detectar si las varianzas son iguales o no. Aceptar $H_0$ indicaría que las varianzas son iguales en las dos muestras.  
  
$H_{0}$: $\sigma^{2}_{Hombres} = \sigma^{2}_{Mujeres}$  
$H_{1}$: $\sigma^{2}_{Hombres} \neq \sigma^{2}_{Mujeres}$

```{r echo=TRUE, message=FALSE, warning=FALSE}
my.vartest <- function(x1, x2, alpha) {
  mean1 <- mean(x1)
  n1 <- length(x1)
  s1 <- sd(x1)
  mean2 <- mean(x2)
  n2 <- length(x2)
  s2 <- sd(x2)
  fobs <- s1^2 / s2^2
  # Range of acceptance.
  fcrit.L <- qf(alpha/2, df1 = n1-1, df2 = n2-1)
  fcrit.U <- qf(1-alpha/2, df1 = n1-1, df2 = n2-1)
  pvalue <- min(pf(fobs, df1=n1-1, df2=n2-1, lower.tail=FALSE ), pf(fobs, df1=n1-1, df2=n2-1))*2
  return(data.frame(fcrit.L, fcrit.U, fobs, pvalue))
}


``` 
  
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
my.vartest(wage.M, wage.F, 0.05)


```

El estadístico fobs está fuera del rango de aceptación de HO, el valor pvalue es menor que el nivel de significancia $\alpha$. Estos dos datos indican que podemos rechazar $H_0$ y con un nivel de confianza del 95% decir que las varianzas de las dos muestras son diferentes.  

Verificamos el resultado con la función var.test. f observado coincide en ambos tests y el valor p value permite rechazar $H_0$ con un nivel de confianza del 95%  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Verify with built-in test.
var.test(wage.M, wage.F)


``` 


Creamos un test para hacer el contraste de hipótesis unilateral por la derecha. Como tenemos varianzas desconocidas y diferentes, tenemos que usar qt y pt para calcular el valor crítico y el valor p.  

```{r echo=TRUE, message=FALSE, warning=FALSE}

my.ttest.2samp <- function(x1, x2, alpha) {
  mean1 <- mean(x1)
  n1 <- length(x1)
  s1 <- sd(x1)
  mean2 <- mean(x2)
  n2 <- length(x2)
  s2 <- sd(x2)
  tobs <- (mean1 - mean2) / sqrt((s1^2/n1) + (s2^2/n2))
  # grades of freedom.
  df <- ((s1^2/n1)+(s2^2/n2))^2 / (((s1^2/n1)^2 / (n1-1)) + ((s2^2/n2)^2 / (n2-1)))
  # Range of acceptance
  tcrit.U <- qt(alpha, df=df, lower.tail = FALSE)
  pvalue <- pt(tobs, lower.tail = FALSE, df=df)
  return(data.frame("INF", tcrit.U, tobs, pvalue, df))
}

```

Aplicamos la función que acabamos de crear  

```{r echo=TRUE, message=FALSE, warning=FALSE}
my.ttest.2samp(wage.M, wage.F, 0.05)


``` 





## Conclusión  

El estadístico observado tobs tiene un valor de 28.8127. Este valor se encuentra fuera del rango de aceptación de $H_0$ y esto lo confirma el pvalue que es lo bastante pequeño (menor que $\alpha$=0.05). Con estos datos podemos rechazar $H_0$ y aceptar $H_1$: con un nivel de confianza del 95% podemos afirmar que los hombres cobran de promedio más a la semana que las mujeres.


## Comprobación  


Comprobamos nuestro resultado con el t.test de R. El valor del estadístico de contraste coincide con el que hemos calculado con nuestro test propio y el valor pvalue también es menor que $\alpha$, por lo tanto podemos rechazar $H_0$

```{r echo=TRUE, message=FALSE, warning=FALSE}
t.test(wage.M, wage.F, alternative = "greater", var.equal = FALSE)


``` 

```{r echo=TRUE, message=FALSE, warning=FALSE}



``` 

```{r echo=TRUE, message=FALSE, warning=FALSE}



```


# Salario semanal (II)  
**¿Podemos aceptar que los hombres cobran al menos 50 euros más que las mujeres en promedio a la semana?**

## Escribid la hipótesis nula y la alternativa    

Formulamos las hipótesis nula y alternativa  
  
**$H_{0}$:** El salario medio de los hombres = el salario medio de las mujeres + 50 euros.  
**$H_{1}$:** El salario medio de los hombres > el salario medio de las mujeres + 50 euros.  



  
## Justificación del test a aplicar  
  
* Tenemos **dos muestras independientes**: hombres y mujeres y realizamos un contraste de hipótesis de dos muestras.  
* Un contraste sobre la **media**.  
* Las **varianzas poblacionales** son **desconocidas**  
* **Test unilateral por la derecha.**  
* Según el Teorema del límite central asumimos la distribución normal de la media muestral (muestra mayor que 30)  
* Las varianzas son diferentes, esto ya lo hemos comprobado en el apartado anterior 
* Aplicamos un Test paramétrico.  

    
## Cálculos  

Aplicamos el ttest con la función que hemos creado antes. 

  
```{r echo=TRUE, message=FALSE, warning=FALSE}
my.ttest.2samp(wage.M, wage.F+50, 0.05)


``` 







## Conclusión  
  
Tenemos tobs igual a 7.65 que se encuentra fuera del rango de aceptación de $H_0$. Por otra parte, pvalue es menor que $\alpha$ (0.05). Con estos datos podemos rechazar $H_0$ a favor de la hipótesis alternativa. Los hombres de media ganan al menos 50 euros más a la semana que las mujeres. Podemos hacer esta afirmación con un nivel de confianza del 95%.  
  
  
## Comprobación  

Comprobamos el resultado con la función t.test de R. El resultado que devuelve la función cuadra con nuestros cálculos. 
  
```{r echo=TRUE, message=FALSE, warning=FALSE}

t.test(wage.M, wage.F+50, alternative = "greater", var.equal = FALSE)

```


# Diferencia de jornada según género
## Análisis visual  
  
Con el comando unique podemos ver que la variable **PartTimeFullTime** tiene dos categorías, "F" (tiempo completo) y "P" (tiempo parcial).  
```{r echo=TRUE, message=FALSE, warning=FALSE}

unique(claim$PartTimeFullTime)

```
  
Visualizamos la variable **PartTimeFullTime** según género, tiempo parcial y tiempo completo.    
```{r echo=TRUE, message=FALSE, warning=FALSE}

ggplot(data=without.unknown, aes(x=Gender, fill=as.factor(PartTimeFullTime)))+geom_bar(position = 'fill')+scale_fill_manual(values = c("purple", "blue"))

``` 




## Interpretación  

Visualmente podemos ver que la proporción de mujeres que trabajan a tiempo parcial es bastante mayor que la proporción de hombres. Casí 25% de las mujeres trabajan a tiempo parcial, mientras solo alrededor de 5% de los hombres trabajan a tiempo parcial.  
  
  
## Hipótesis nula y alternativa  
**¿La proporción de personas que trabajan a tiempo completo es diferente para hombres que para mujeres?**  

**$H_0$:** $p_{Hombres} = p_{Mujeres}$  
La proporción de personas que trabajan a tiempo completo es la misma para hombres que para mujeres.  
  
**$H_1$:** $p_{Hombres} \neq p_{Mujeres}$  
La proporción de personas que trabajan a tiempo completo es diferente para hombres que para mujeres.


  
## Tipo de test  

* Tenemos **dos muestras independientes**: la proporción de personas que trabajan a tiempo completo de hombres y de mujeres y realizamos un contraste de hipótesis de dos muestras.  
* Un contraste sobre la **proporción**.  
* **test bilateral** la proporción es igual o no.
* Asumimos las proporciones muestrales presentan una **distribución aproximadamente normal** ya que las muestras son lo suficientemente grande.
 
  
  
## Cálculos  
  
  
Creamos los dos muestras(M=hombres, W=mujeres). Calculamos el número de observaciones y la proporción de personas que trabajan a tiempo completo para ambos sexos.  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Men
M <- claim[claim$Gender=="M",]
# Women
W <- claim[claim$Gender=="F",]

# Calculate number of observations for men.
nM <- nrow(M)
# Calculate number of observations for women.
nW <- nrow(W)

# Calculate the proportion full time job men.
pM <- sum(M$PartTimeFullTime=="F") / nM
# Calculate the proportion full time job women
pW <- sum(W$PartTimeFullTime=="F") / nW

```
  
  
Creamos un test para hacer el contraste de hipótesis bilateral.  
```{r echo=TRUE, message=FALSE, warning=FALSE}
my.prop.test <- function(p1, p2, n1, n2, alpha) {
  # calculate p parameter.
  p <- (n1*p1 + n2*p2) / (n1+n2)
  

  
  # Observed.
  zobs <- (p1 - p2) / (sqrt(p*(1-p)*(1/n1+1/n2)))

  
  # Range of acceptance.
  zcrit.U <- qnorm(1-alpha/2)
  zcrit.L <- qnorm(alpha/2)
  
  # p-value
  pvalue <- pnorm(zobs, lower.tail = FALSE)*2
  
  return(data.frame( zcrit.L, zcrit.U,zobs, format(pvalue, scientific=TRUE)))
}


``` 


Aplicamos la función que acabamos de crear.  
```{r echo=TRUE, message=FALSE, warning=FALSE}

my.prop.test(pM, pW, nM, nW, 0.05)

```




## Conclusión  


Hemos hecho un contraste de hipótesis sobre la proporción para determinar si la proporción de hombres que trabajan a tiempo completo es igual que la proporción de mujeres que trabajan a tiempo completo. En la visualización que creamos para tener una primera idea de la respuesta podíamos ver que la proporción de mujeres que trabajan a tiempo parcial es mucho mayor que la de los hombres. 

El resultado del contraste de hipótesis es que el valor zobs es de 57.34 y se encuentra fuera del rango de aceptación de la hipótesis nula. Podemos confirmar esto con el valor pvalue que es igual a cero. 

Los datos que obtuvimos del contraste de hipótesis nos permiten responder a la pregunta de investigación con un nivel de confianza del 95% que la proporción de personas que trabajan a tiempo completo es diferente para hombres y mujeres. 
  
## Comprobación  
  
Comprobamos el resultado con la función prop.test

```{r echo=TRUE, message=FALSE, warning=FALSE}

success <- c(pM*nM, pW*nW)
nn <- c(nM, nW)

prop.test(x=success, n=nn, alternative="two.sided", correct=FALSE, conf.level = 0.95)


``` 


  
  
  
  
  
  
# Salario por hora  
**¿Podemos afirmar que los hombres cobran más que las mujeres por hora trabajada?**
  
  
## Hipótesis nula y alternativa  
  
**$H_0$:** El salario por hora de los hombres = el salario por hora de las mujeres.  
  
**$H_1$:** El salario por hora de los hombres > el salario por hora de las mujeres.
 

## Tipo de test  
  
* Tenemos **dos muestras independientes**: el salario por hora de hombres y de mujeres y realizamos un contraste de hipótesis de dos muestras.  
* Un contraste sobre la **media**.  
* Las **varianzas poblacionales** son **desconocidas**  
* **Test unilateral por la derecha.**  
* Según el Teorema del límite central asumimos la distribución normal de la media muestral (muestra mayor que 30)  
* Aplicamos un Test paramétrico.  
* No sabemos si las varianzas muestrales son iguales o no, tendremos que hacer un **test de homoscedasticidad**.  
  
## Cálculos  
  
Creamos la variable HourlyWages para guardar el sueldo por hora. 

```{r echo=TRUE, message=FALSE, warning=FALSE}


claim$HourlyWages <- claim$WeeklyWages / claim$HoursWeek
``` 



Obtenemos dos muestras de datos: para hombres y mujeres. Guardamos estas muestras en sus respectivas variables
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Men
prhour.M <- claim$HourlyWages[claim$Gender=="M"]
prhour.W <- claim$HourlyWages[claim$Gender=="F"]


``` 

Comprobamos si las varianzas de las dos muestras son iguales o no
  
Haemos el test de homoscedasticidad para comprobar si las varianzas en las dos muestras son diferentes.
  
$H_{0}$: $\sigma^{2}_{Hombres} = \sigma^{2}_{Mujeres}$  
$H_{1}$: $\sigma^{2}_{Hombres} \neq \sigma^{2}_{Mujeres}$  

```{r echo=TRUE, message=FALSE, warning=FALSE}
my.vartest(prhour.M, prhour.W, 0.05)


``` 
Tenemos un pvalue menor que $\alpha$, con esto podemos concluir que estaremos comentiendo un error pequeño al rechazar la hipótesis nula. Esto está respaldado por el valor de fobs que está fuera del intervalo de aceptación de $H_0$. 
  
Comprobamos el resultado con el var.test de R. El valor pvalue en este test también permite rechazar $H_0$.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Verify with built-in variance test.
var.test(prhour.M, prhour.W)


``` 

Usamos el test que hemos creado anteriormente para comprobar si los salarios por hora para hombres y mujeres son iguales o no.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
my.ttest.2samp(prhour.M, prhour.W, 0.05)


``` 
  


En esta ocasión tenemos el estadístico observado tobs dentro del rango de aceptación de $H_0$ y el valor pvalue es mayor que $\alpha$ (0.05). Estos datos no nos permiten rechazar $H_0$.


## Conclusión   


Hemos realizado el contraste de hipótesis sobre si el salario por hora de los hombres es igual o no al salario por hora de las muejeres. El valor pvalue y el estadístico observado (dentro del rango de aceptación de $H_0$) indican que no tenemos que rechazar la hipótesis nula y que no hay diferencia entre el salario por hora de los hombres y de las mujeres. Podemos hacer esta afirmación con un nivel de confianza del 95%.  


## Comprobación  

Hacemos la comprobación con la función t.test de R.  

Podemos ver que los valores de tobs y pvalue coinciden.  

```{r echo=TRUE, message=FALSE, warning=FALSE}

t.test(prhour.M, prhour.W, alternative = "greater", var.equal = FALSE)

``` 


# Resumen ejecutivo  

En esta práctica hemos aplicado la estadística inferencial y hemos realizado todas las comprobaciones previas.


En primer lugar, analizamos la variable UltCost que sigue una distribución con la mayoría de valores más cercanos a cero y una cola larga a la derecha. Tras aplicar la tranformación logarítmica pudimos ver que la variable tranformada sigue una distribución muy parecida a la normal y esto se confirmó con el qqplot. 

Calculamos el intervalo de confianza para UltCost (9938.86 - 10356.48). Este es el intervalo en el que se encontrará la media poblacional del 95% de las muestras que podamos tomar. 


En todos los ejercicios siguientes el objetivo final es comprobar si existen diferencias entre los hombres y las mujeres en sueldo y jornada y si es así, si alguno de los géneros tiene mayor sueldo por unidad de tiempo trabajada que otro.

**Resumen**: 

Después de realizar los tests hemos encontrado que el sueldo semanal para hombres es mayor que para mujeres, pero afirmar esto puede ser peligroso si no hacemos más comrobaciones, como por ejemplo, si los hombres y las mujeres trabajan números de horas similares para ganar sueldos diferentes. Resultó que la proporción de mujeres que trabaja a tiempo parcial es mayor que la de los hombres (así se ve en el histograma, el contraste solamente responde que las proporciones son diferentes) y esta diferencia en tipo de jornada podría ser la razón por la que los hombres ganan más (trabajan más horas). La comprobación definitiva para responder a la pregunta de igualdad fue el cálculo del salario por horas y un contraste sobre este variable. En esta ocasión sí vemos que los sueldos por hora son iguales para hombres y para mujeres, así que realmente no hemos detectado ninguna injusticia (con un nivel de confianza del 95%).



**En detalle los pasos seguidos en los contrastes**:


*Diferencias entre coste final y coste inicial*.  
Para responder a la pregunta de si existen diferencias entre IniCost y UltCost hemos hecho un contraste de hipótesis bilateral de una muestra (UltCost - IniCost). El contraste ha revelado que sí *hay diferencia entre los dos costes*, aunque no sabemos si es positiva o negativa. Esto lo podemos afirmar con un nivel de confianza del 95%.
  
*Diferencia de salario semanal entre hombres y mujeres*.   

También queríamos responder a la pregunta de si existen diferencias en el sueldo semanal entre hombres y mujeres. En el diagrama no detectamos grandes diferencias y procedemos a realizar un contraste de hipótesis donde la hipótesis nula es que los sueldos semanales son iguales entre sexos y la hipótesis alternativa es que los hombres ganan más. Se trata un contraste sobre la media, unilateral por la derecha de dos muestras independientes, con varianzas desconocidas y diferentes (y para saber si son iguales o diferentes realizamos un contraste) y con la asunción de que la media muestral sigue una distribución normal. El resultado del contraste ha sido la aceptación de la hipótesis alternativa con un nivel de confianza del 95%: **los hombres ganan a la semana de media más que las mujeres**.  

*Diferencia de salario (parte II)*.  

En esta ocasión ya sabemos que las varianzas son diferentes. Podemos hacer las mismas asunciones que hemos hecho en la primera parte del ejercicio. El resultado del contraste es que con un nivel de confianza del 95% podemos rechazar la hipótesis nula: **los hombres ganan más de 50 euros más a la semana que las mujeres**.  

*Diferencia de jornada según género*.  

Los gráficos que usamos para visualizar las proporciones de hombres y mujeres que trabajan a tiempo parcial muestran claramente que hay más muejeres que usan este tipo de jornada laboral. El contraste que aplicamos es un contraste sobre la proporción, bilateral de dos muestras independientes con asunción de normalidad en la distribución de la media muestral. El resultado: con un nivel de confianza del 95% podemos afirmar que **las proporciones de hombres y mujeres que trabajan a tiempo completo son diferentes**.  



Comprobamos si el *salario por hora* es igual para los hombres y las mujeres o los hombres ganan más por hora que las mujeres. Usamos un test sobre la media, unilateral por la derecha de dos muestras independientes con varianzas desconocidas y diferentes. El resultado del test es que con un nivel de confianza del 95% podemos afirmar que **los hombres ganan lo mismo por hora que las mujeres**.  

