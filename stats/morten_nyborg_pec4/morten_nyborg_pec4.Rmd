---
title: "A4 - Análisi de varianza y repaso del curso"
author: "Autor: Morten Nyborg"
date: "Diciembre 2021"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
  word_document: default
  pdf_document:
    highlight: zenburn
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
if(!require(agricolae)){
    install.packages('agricolae',repos='http://cran.es.r-project.org')
    require(agricolae)
}
if(!require(car)){
    install.packages('car',repos='http://cran.es.r-project.org')
    require(car)
}
if(!require(dplyr)){
    install.packages('dplyr',repos='http://cran.es.r-project.org')
    require(dplyr)
}
if(!require(nortest)){
    install.packages('nortest',repos='http://cran.es.r-project.org')
    require(nortest)
}
if(!require(MASS)){
    install.packages('MASS',repos='http://cran.es.r-project.org')
    require(MASS)
}
if(!require(plyr)){
    install.packages('plyr',repos='http://cran.es.r-project.org')
    require(plyr)
}
if(!require(tidyverse)){
    install.packages('tidyverse',repos='http://cran.es.r-project.org')
    require(tidyverse)
}


```

# Introducción  
  
Este conjunto de datos contiene información de una muestra extraída a partir de un censo, en el que para cada persona, se registran los salarios aparte de información personal adicional. El conjunto de datos contiene
32.560 registros y 9 variables.
Las variables de esta muestra son:

* Age: Edad del individuo.  
* Workclass: Categorización del individuo en base al perfil laboral.  
* Education_num: Número de años de formación educativa del individuo.  
* Marital_status: Estado civil del individuo.  
* Occupation: Categorización del individuo en base a la tipología de trabajo.  
* Race: Grupo racial al que pertenece el individuo.  
* Sex: Género del individuo.  
* hours_per_week: Horas por semana trabajadas por el individuo.  
* income: Salario (anual) del individuo, en k€.  
  
# Lectura del archivo y preparación de los datos  
**Leer el archivo CensusIncomedada.txt y guardar los datos en un objeto con identificador denominado adult. A continuación, verifica que los datos se han cargado correctamente.**
  
Cargamos el dataset y guardamos los datos en el objeto "adult".    
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Loading data
adult <- read.csv('./CensusIncomedata.txt', header = TRUE, sep = " ")

# Get the dimensions of dataset.
dim(adult)

# Verify the dataset has loaded correctly.
problems(adult)

# Printing the variables with its datatypes.
str(adult)

# Column names.
names(adult)

# Show 6 first rows.
head(adult)
```  
## Preparación de los datos  
**Fíjate en los valores de las variables categóricas para identificar y proceder a quitar los molestos espacios en blanco al inicio de los valores.**  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Save categorical column names in a variable.
cat.colnames <- colnames(adult[unlist(lapply(adult, is.character))])

# Identify unique values for each of them.
lapply(adult[cat.colnames], unique)

# Remove leading and trailing whitespaces.
adult[cat.colnames] <- lapply(adult[cat.colnames], trimws)

# Verify the trim of whitespaces.
lapply(adult[cat.colnames], unique)
```  

**Corrige el error en el nombre de la séptima variable, ya que realmente nos queremos referimos al rol social o percepción individual del género propia del individuo. (https://en.wikipedia.org/wiki/Sex_and_gender_distinct)**  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Change name of column 7 to gender.
colnames(adult)[7] <- "gender"

# Verify.
colnames(adult)[7]

``` 
  
**¿Qué podemos afirmar sobre la normalidad de la variable salario? Ayúdate de la inspección visual y el test conocido de Lilliefors.**   


Según el QQ plot, la variable income no sigue una distribución normal. Una distribución normal estaría reflejada por los puntos ajustados junto a los cuantiles teoricos de la distribución normal (línea diagonal). En el histograma tampoco prece una distribución normal, parece que hay dos máximos locales.  

El lillie.test es un test de normalidad, donde la hipótesis nula validada indicaría que la variable sigue una distribución normal. En este caso hemos hecho el test y tenemos un p-value que nos permite rechazar la hipótesis nula, no existe normalidad en la distribución de la variable income (con un nivel de confianza del 95%)   
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Plotting histogram of income.
truehist(adult$income, main = 'Distribution of income', col = "orange")

# Plot of quantiles.
qqnorm(adult$income, main = 'Income', col = "green")
qqline(adult$income)

# Lilliefors test.
lillie.test(adult$income)
``` 


  
**Genera una variable denominada ‘Less50‘ que clasifique binariamente los salarios dado el límite de 50k€. Como hemos dicho antes, focalizamos sobre tener un ingreso menor en esta cantidad (‘Less50‘), y por tanto, codificaremos la variable ‘Less50‘ con el valor 1 cuando el salario sea inferior a 50k€, e igual a 0 en caso contrario.**  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Create the variable 'Less50'.
adult$Less50 <- ifelse(test = adult$income < 50, yes = 1, no = 0)

# Verify.
head(adult[c("income", "Less50")])
``` 




## Análisis visual 
**1. Muestra con varios diagramas de caja la distribución de la variable income según las variables gender, race, workclass, marital_status y occupation.**
```{r echo=TRUE, message=FALSE, warning=FALSE, fig.width=10, fig.height=6}
# plotting the boxplots.


boxplot(adult$income~adult$gender, main = "Income according to gender.", col="orange")

boxplot(adult$income~adult$race, main = "Income according to race.", col="orange", cex.axis=0.7)

boxplot(adult$income~adult$workclass, main = "Income according to workclass", col="orange")

boxplot(adult$income~adult$marital_status, main = "Income according to marital status.", col="orange")

boxplot(adult$income~adult$occupation, main = "Income according to occupation.", col="orange", cex.axis=0.7)
```  
  
**2. Interesa visualizar también las variables age, hours_per_week y education_num.**
  
```{r echo=TRUE, message=FALSE, warning=FALSE, fig.width=10, fig.height=6}
# Age vs income.
ggplot(adult, aes(age, income))+ geom_point(alpha=0.1, color="blue")+ ggtitle("Age vs Income")+theme(plot.title = element_text(hjust = 0.5))

# Hours_per_week vs Income.
ggplot(adult, aes(hours_per_week, income))+ geom_point(alpha=0.1, color="blue")+ ggtitle("Hours per week vs Income")+theme(plot.title = element_text(hjust = 0.5))

# Education_num vs Income.
ggplot(adult, aes(education_num, income))+ geom_point(alpha=0.1, color="blue")+ ggtitle("Education number vs Income")+theme(plot.title = element_text(hjust = 0.5))
```

  
**3. Interpreta los gráficos brevemente. Aprovecha que las últimas variables son continuas para interpretar su tendencia.**    


Diagramas de cajas de income según otras variables:  


*Gender*: personas del género masculino tienen la mediana notablemente más alta. Las personas de género femenino que más ganan (Q3 + 1.5IQR) ganan aproximadamente igual que la persona mediana de género masculino.   

*Raza*: Las personas de raza blanca son las que mayores ingresos tienen, las que menos ganan son personas de otras razas. Otra vez, las personas blancas que se encuentran cerca del Q3 ganan aproximadamente tanto como pueden ganar las personas de otras razas en el mejor de los casos (según los datos). Hay que notar que Q1-1.5IQR para personas blancas es tan bajo como el de las razas que no son "Other", es decir, hay personas blancas que ganan poco, no todos los blancos ganan mucho.  

*Workclass*: Las personas que trabajan en el sector público ganan más que las del sector privado. Las que trabajan en sectores desconocidos ganan menos.  

*Estado civil*: Las personas casadas ganan más que todas las demás y este es uno de los niveles que muestra muchos outliers: hay muchas personas casadas que ganan muy poco, son outliers.  

*Ocupación*: otra vez las ocupaciones desconocidas son las que menores ingresos muestran. White collar parece que tiene mejores ingresos, blue collar también, pero los cuantiles son más compactos.  


Cuantitativas: 

*Edad*: Hay muchas personas jóvenes, los ingresos parece que tienden a subir desde la edad más jóven hasta los 50 años aproximadamente, después de esta edad tenemos menos personas en el dataset, las personas que tenemos ganan menos y menos con la edad.  

*Horas semanales*: la mayoría trabaja 40 horas semanales, aunque hay opciones de más y de menos bastante populares. Los que trabajan 40 horas pueden tener todo tipo de ingresos desde 30 a 65k, que parece que son habituales por la intensidad del color.  

Las personas que trabajan menos de 40 horas también pueden ganar hasta 65k, pero no es lo habitual. para personas que trabajan más de 20 y menos de 40 horas el rango está sobre 35-55k.  

Trabajar muchas más horas que 40 aumenta el ingreso mínimo pero no mejora el máximo. Tenemos que las personas que trabajan muchas horas tienen ingresos máximos menores que las que trabajan pocas.  

*Nùmero de educación*: niveles hasta el 9 hacen que aumente el ingreso máximo, a partir del 9 aumenta el ingreso mínimo, el máximo parece quedarse relativamente constante.  

Las personas con nivel educativo muy alto tienen unos ingresos por lo general bastante medios, también será que tenemos pocas personas en esta categoria. 

# Estadística inferencial  
## Contrastes de hipótesis 
  
**Nos interesamos ahora por las potenciales diferencias en el salario de los individuos para diferentes grupos, en particular, las mujeres y los hombres, y los grupos raciales blanco y negro.**  
**- ¿Cobran los hombres más que las mujeres? Responde a la pregunta con un nivel de confianza del 95%.**  
**- ¿Cobra la gente blanca 6450€ más al año que la gente negra? Responde a la pregunta con un nivel de confianza del 95%.**   
  
Creamos las muestras por el caso género.  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Create the two sample male and female wage.
wage.M <- adult$income[adult$gender=="Male"]
wage.F <- adult$income[adult$gender=="Female"]

``` 
  
Creamos las muestras por el caso racial.    
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Create the two sample black and white wage.
wage.W <- adult$income[adult$race=="White"]
wage.B <- adult$income[adult$race=="Black"]

``` 
  
### Hipótesis nula y alternativa (por el género y por el caso racial)  
  
**1.) El caso género.**  
  
**$H_0$:** El salario medio al año de los hombres $=$ El salario medio al año de las mujeres  
**$H_1$:** El salario medio al año de los hombres $>$ El salario medio al año de las mujeres  
  
  
**2.) El caso racial.**  
  
**$H_0$:**   El salario medio al año de la gente blanca $=$ El salario medio al año de la gente negra + 6.450k€  
**$H_1$:**   El salario medio al año de la gente blance $>$ El salario medio al año de la gente negra + 6.450k€  
  
### Justificación del test a aplicar (por el género y por el caso racial)  
  
Calculamos la frecuencia de los valores diferentes para las variables "gender" y "race". Podemos ver que todos los valores de la gente blanca, de la gente negra, de los hombres y de las mujeres tienen una muestra > 30. Con esto nos podemos acoger al teorema del límite central que afirma que si la muestra es lo suficientemente grande (mayor que 30), incluso si la población de la que proviene la muestra no sigue una distribución normal, la media muestral sí que la seguira. Así podemos asumir la normalidad de la distribución de la media muestral en género y raza.  


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Frequency of gender and race.
count(adult, 'gender')
count(adult, 'race')
```  
  
**1.) El caso género.**  
  
* Tenemos **dos muestras independientes**: mujeres y hombres y ejecutamos un contraste de hipótesis de dos muestras.  
* **Test unilateral por la derecha.**  
* Un contraste sobre la **media**.  
* Según el Teorema del límite central asumimos la **distribución normal** de la media muestral (muestra mayor que 30).  
* Usaremos un **test paramétrico**.  
* Las **varianzas poblacionales** son **desconocidas**  
* No sabemos si las varianzas muestrales son iguales o no, tendremos que hacer un **test de homocedasticidad**.  
  
  
**2.) El caso racial.**  
  
* Tenemos **dos muestras independientes**: la gente blanca y la gente negra y ejecutamos un contraste de hipótesis de dos muestras.  
* **Test unilateral por la derecha**. La gente blanca cobra al menos 6450€ más al año que la gente negra o no.  
* Un contraste sobre la **media**.  
* Según el Teorema del límite central asumimos la **distribución normal** de la media muestral (muestra mayor que 30).  
* Usaremos un **test paramétrico**.  
* Las **varianzas poblacionales** son **desconocidas**  
* No sabemos si las varianzas muestrales son iguales o no, tendremos que hacer un **test de homocedasticidad**.   
  
### Aplicación, interpretación y comprobación del test (por el género y por el caso racial)  
  
**1.) El caso género.**  
  
Realizamos un test de homocedasticidad para detectar si las varianzas son iguales o no. Aceptar $H_0$ indicaría que las varianzas son iguales en las dos muestras.  
  
$H_{0}$: $\sigma^{2}_{Hombres} = \sigma^{2}_{Mujeres}$  
$H_{1}$: $\sigma^{2}_{Hombres} \neq \sigma^{2}_{Mujeres}$  


```{r echo=TRUE, message=FALSE, warning=FALSE}
my.vartest <- function(x1, x2, alpha) {
  mean1 <- mean(x1)
  n1 <- length(x1)
  s1 <- sd(x1)
  mean2 <- mean(x2)
  n2 <- length(x2)
  s2 <- sd(x2)
  fobs <- s1^2 / s2^2
  # Range of acceptance.
  fcrit.L <- qf(alpha/2, df1 = n1-1, df2 = n2-1)
  fcrit.U <- qf(1-alpha/2, df1 = n1-1, df2 = n2-1)
  pvalue <- min(pf(fobs, df1=n1-1, df2=n2-1, lower.tail=FALSE ), pf(fobs, df1=n1-1, df2=n2-1))*2
  return(data.frame(fcrit.L, fcrit.U, fobs, pvalue))
}

```  


```{r echo=TRUE, message=FALSE, warning=FALSE}
my.vartest(wage.M, wage.F, 0.05)
```
  
El estadístico **fobs** está fuera del rango de aceptación de $H_0$, el **pvalue** es menor que el nivel de significancia $\alpha$. Estos dos datos indican que podemos rechazar $H_0$ y con un nivel de confianza del 95% decir que **las varianzas de las dos muestras son diferentes**.  
  
Comprobamos con la función var.test de R.   
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Verify with built-in test.
var.test(wage.M, wage.F)

``` 
  
Creamos un test para hacer el contraste de hipótesis unilateral por la derecha. Como tenemos varianzas desconocidas y diferentes, tenemos que usar qt y pt para calcular el valor crítico y el valor p.  
```{r echo=TRUE, message=FALSE, warning=FALSE}

my.ttest <- function(x1, x2, alpha) {
  mean1 <- mean(x1)
  n1 <- length(x1)
  s1 <- sd(x1)
  mean2 <- mean(x2)
  n2 <- length(x2)
  s2 <- sd(x2)
  tobs <- (mean1 - mean2) / sqrt((s1^2/n1) + (s2^2/n2))
  # grades of freedom.
  df <- ((s1^2/n1)+(s2^2/n2))^2 / (((s1^2/n1)^2 / (n1-1)) + ((s2^2/n2)^2 / (n2-1)))
  # Range of acceptance
  tcrit.U <- qt(alpha, df=df, lower.tail = FALSE)
  pvalue <- pt(tobs, lower.tail = FALSE, df=df)
  return(data.frame("INF", tcrit.U, tobs, pvalue, df))
  
}

``` 
  
Aplicamos la función que hemos creado.    
```{r echo=TRUE, message=FALSE, warning=FALSE}

my.ttest(wage.M, wage.F, 0.05)
``` 
  
El estadístico observado tobs tiene un valor de 194.1. Este valor se encuentra fuera del rango de aceptación de $H_0$ y esto lo confirma el pvalue que es pequeño (menor que $\alpha$=0.05). Con estos datos podemos rechazar $H_0$ y aceptar $H_1$: con un nivel de confianza del 95% podemos afirmar que los hombres cobran más que las mujeres.  
  
Verificamos nuestro resultado con la función t.test de R. El valor del estadístico de contraste coincide con el que hemos calculado con nuestro test propio y el valor pvalue también es menor que $\alpha$, por lo tanto podemos rechazar $H_0$  


```{r}
t.test(wage.M, wage.F, alternative = "greater", var.equal = FALSE)
```


**2.) El caso racial.**  

Realizamos un test de homocedasticidad para detectar si las varianzas son iguales o no. Aceptar $H_0$ indicaría que las varianzas son iguales en las dos muestras.  
  
$H_{0}$: $\sigma^{2}_{Blanca} = \sigma^{2}_{Negra}$  
$H_{1}$: $\sigma^{2}_{Blanca} \neq \sigma^{2}_{Negra}$  
  
Utilizamos la función my.vartest de el caso género.  
```{r echo=TRUE, message=FALSE, warning=FALSE}
my.vartest(wage.W, wage.B, 0.05)
```

El estadístico fobs está fuera del rango de aceptación de $H_0$, el valor es menor que el nivel de significancia $\alpha$. Estos dos datos indican que podemos rechazar $H_0$ y con un nivel de confianza del 95% decir que las varianzas de las dos muestras son diferentes.  
  
Comprobamos con la función var.test de R.   
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Verify with built-in test.
var.test(wage.W, wage.B)

```



Aplicamos la función que hemos creado anteriormente ya que tenemos varianzas diferentes de las dos muestras y un test unilateral por la derecha.

```{r}
my.ttest(wage.W, wage.B+6.450, 0.05)
```

El estadístico observado tobs tiene un valor de 2.037 Este valor se encuentra fuera del rango de aceptación de $H_0$ y esto lo confirma el pvalue que es lo pequeño (menor que $\alpha$=0.05). Con estos datos podemos rechazar $H_0$ y aceptar $H_1$: con un nivel de confianza del 95% podemos afirmar que la gente blanca cobra al menos 6.450k€ más que la gente negra.  
  
Verificamos nuestro resultado con la función t.test de R. El valor del estadístico de contraste coincide con el que hemos calculado con nuestro test propio y el valor pvalue también es menor que $\alpha$, por lo tanto podemos rechazar $H_0$ 



```{r echo=TRUE, message=FALSE, warning=FALSE}
t.test(wage.W, wage.B+6.450, alternative = "greater", var.equal = FALSE)

``` 

 



# Modelo de regresión lineal  
## Estimación de modelos  
  
**Estima un modelo de regresión lineal múltiple que tenga como variables explicativas: age, education_num, hours_per_week y gender, y como variable dependiente el Income.**  
  
  
Creamos el modelo model_1 para predicir "income" usando "age", "education_num", "hours_per_week" y "gender" como variables explicativas.  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Set gender as factor.
adult$gender <- as.factor(adult$gender)

```  


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Create model.
model_1 <- lm(income ~ age + education_num + hours_per_week + gender, data = adult)

# Print summary of model.
summary(model_1)
``` 
  
**Genera un segundo modelo pero esta vez añadiendo la variable race.**  
  
Creamos un modelo nuevo model_2 por añadir la variable explicativa "race".    
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Set race as factor
adult$race <- as.factor(adult$race)

``` 

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Build model
model_2 <-  lm(income ~ age + education_num + hours_per_week + gender + race, data = adult)

# Print summary of model_2.
summary(model_2)

``` 





## Interpretación de los modelos  
  
**Interpreta los modelos lineales ajustados y valora la calidad del ajuste:**  
  
* **Valora la significación de las variables explicativas.**  
  
  Modelo 1:  
  Todas las variables "age", "education_num"y "hours_per_week" y la variable dummy "genderMale" son significativas porque sus pvalues que nos devuelve el modelo son menores que 0.05.  
  
  Modelo 2: todas las variables son significativas, excepto la variable dummy race - Asian pacific islander, su pvalue es de 0.418.   
  
* **Explica la contribución de las variables explicativas en el modelo.**  

  Modelo 1:  
  Todas las variables tienen coeficientes positivos, esto significa que un aumento en el valor de la variable implica un aumento en el valor de la variable predicha. La variable education number es la que mayor influencia tiene sobre los ingresos, su coeficiente es 0.45.  
  La variable que representa el sexo masculino tiene una influencia positiva con un coeficiente 10.1. Es la variable con mayor coeficiente. Ser hombre aumenta los ingresos.
  
  Modelo 2:  
  Las variables dummy "raceAsian-Pac-Islander", "raceOther" tienen coeficientes negativos, un aumento en el valor de estas variables lleva a la reducción de los ingresos.De estas dos variables solamente "raceOther" es significativa.   
  La variable que representa el sexo masculino también tiene un influencia positiva muy fuerte sobre los ingresos.  
  
* **¿La inclusión de la variable race ha supuesto una mejora del segundo modelo respecto al primero?**  

  Incluir la variable que representa la raza ha aumentado el valor de $R^2$ en el modelo 2 con respecto al modelo 1 y la proporción de la varianza explicada por el modelo ha aumentada.   


  Modelo 1: $R^2$ = 0.59
  Modelo 2: $R^2$ = 0.67

  
## Análisis de residuos  
  
**Por último, para profundizar en la calidad del ajuste deben analizarse los residuos que nos indicarán realmente cómo se ajusta nuestro modelo a los datos muestrales. Lo haremos sólo por el segundo de los modelos lineales obtenidos.**  
  
* **La salida de ‘summary()‘ presenta los principales estadísticos de la distribución de los residuos. Analiza los valores estimados de los estadísticos.**    


La media de los residuos es igual a cero, la mediana es de 0.008.   
La distribución parece bastante simétrica con respecto a la media, el mínimo es de -15.3 y el máximo de 16.1.   
Los cuartiles 1 y 3 son de -2.8 y 2.8, son simetricos con respecto a la media.  

En una distribución normal la media es igual a cero, la media es igual a la mediana y los valores se distribuyen de forma simetrica con respecto al cero.   
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Basic stats residuals.
summary(model_2$residuals)


```  



  
* **Realiza ahora un análisis visual de los residuos. ¿Qué podemos decir sobre la bondad de la adecuación del modelo?**    

Los residuos son bastante simetricos con respecto al cero. Para valores bajos de valores ajustados los residuos tienden a ser mayores que cero.   

Los residuos no se distribuyen de forma totalmente aleatoria, existe una forma de la nube de puntos que visualizamos y también una tendencia que podemos ver a través de la línea roja.  

Entre los valores 45 y 50 existen más residuos negativos que positivos, para valores entre 40 y 45, 50 y 55 los residuos son más simétricos.  


  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# 
plot(model_2, which = 1)
``` 

El gráfico qqplot muestra la distribución que siguen los residuos frente a los cuantiles teoricos de una distribución normal. Los residuos se distribuyen de forma muy parecida a una distribución normal, en los valores más extremos existe una desviación.  

```{r echo=TRUE, message=FALSE, warning=FALSE}

plot(model_2, which = 2)
```


El gráfico muestra la distribución de los residuos estandarizados. En este caso la línea roja es más horizontal, indica que la varianza es constante.  

Este gráfico sirve para ver la homocedasticidad. La distribución de los residuos es simétrica con respecto a la línea horizontal.  

```{r echo=TRUE, message=FALSE, warning=FALSE}

plot(model_2, which = 3)
```  




## Predicción  
  
**De nuevo, sólo por el segundo modelo estimado, realiza la predicción del income esperado para las siguientes características: age=24, education_num= “4”, hours_per_week=“40”, gender=" Female“, race=”Black". Proporciona, además, el intervalo de confianza del 95%.**  
  
Creamos un data frame con los datos proporcionados en el enunciado y lo usamos para predecir los valores de "income".  
  
Con edad de 24, número de educación de 4, horas por semana de 40, género de mujer y raza de negra el modelo estima que el nivel de ingreso es de 34.970k€.  
  
El intervalo de confianza (34.785, 35.15627) significa el rango en el que el parámetro de la población real se encuentra con un nivel de confianza de 95%.   


```{r echo=TRUE, message=FALSE, warning=FALSE}
newdata = data.frame(age=24, education_num=4, hours_per_week=40, gender="Female", race="Black")

predict(model_2, newdata, interval = "confidence")
```  



# Regressión logística  
  
Utilizando las variables explicativas posibles, ajusta un modelo predictivo basado en la regresión logística para predecir la probabilidad de tener un salario menor de 50 k€. Por eso, usaremos la variable dicotómica Less50 que ha creado en el primer apartado, que será nuestra variable dependiente del modelo.  

Para poder estimar de forma más objetiva la precisión del modelo, separaremos el conjunto de datos en dos partes: el conjunto de entrenamiento (training) y el conjunto de prueba (test). Ajustaremos el modelo de regresión logística con el conjunto de entrenamiento, y evaluaremos la precisión con el conjunto de prueba.

Siga los pasos que se especifican a continuación.  
– Generar los conjuntos de train y test  
– Entrena el modelo  
– Interprete el modelo entrenado  
– Evalúe la calidad del modelo sobre los datos de test  
– Predición    
  
## Generación de los conjuntos de entrenamiento y de test  
  
**Genere los conjuntos de datos para entrenar el modelo y para testarlo. Puedes fijar el tamaño de la muestra de entrenamiento a un 80% del original.**  
  


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Creates the value for training set.
samp_size <- floor(0.8*nrow(adult))

set.seed(24)

# Index for train dataset.
train.idx <- sample(seq_len(nrow(adult)), size = samp_size)

# Create training dataset.
train.reg <- adult[train.idx,]

# Create test dataset.
test.reg <- adult[-train.idx,]

```  



## Modelo predictivo  
  
**Entrene el modelo con el conjunto que acaba de generar. Utilice, como valores de referencia, el valor mayoritario de cada variable. Por ejemplo, para race, utilizaremos White.**  
  
  
Guardamos estos datos como factores en los conjuntos de entrenamiento y test. 
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Set categorical variable as factor.
train.reg$workclass <- as.factor(train.reg$workclass)
test.reg$workclass <- as.factor(test.reg$workclass)

train.reg$marital_status <- as.factor(train.reg$marital_status)
test.reg$marital_status <- as.factor(test.reg$marital_status)

train.reg$occupation <- as.factor(train.reg$occupation)
test.reg$occupation <- as.factor(test.reg$occupation)

```  

Podemos ver que las variables se han guardado como factores.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
str(train.reg)

``` 


Contamos las observaciones que tiene cada nivel del factor en las variables. 
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Get frequency of categorical variables.
count(adult$workclass)
count(adult$race)
count(adult$marital_status)
count(adult$gender)
count(adult$occupation)
``` 

Aplicamos relevel a todas las variables tipo factor, usamos como referencia el nivel más frecuente.  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Re-level categorical variable. Set base case most frequent.
train.reg$workclass <- relevel(train.reg$workclass, ref = 'Private')
train.reg$race <- relevel(train.reg$race, ref = 'White')
train.reg$marital_status <- relevel(train.reg$marital_status, ref = 'Married')
train.reg$gender <- relevel(train.reg$gender, ref = 'Male')
train.reg$occupation <- relevel(train.reg$occupation, ref = 'Blue-Collar')

``` 


Creamos el modelo que explica los ingresos mayores o menores de 50k en función de otras variables. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Building the model.
model.reg <- glm(formula = Less50~age+workclass+education_num+marital_status+occupation+race+gender+hours_per_week, data = train.reg, family = binomial(link = logit) )

# Print summary
summary(model.reg)

```


## Interpretación  
  
**Interpreta el modelo ajustado. Concretamente, explica la contribución de las variables explicativas con coeficiente estadísticamente significativo para predecir el salario de los individuos.**  
  
  
Todas las variables son significativas para el modelo. Las variables que tienen influencia negativa en la probabilidad de ganar menos que 50k son la edad, ser trabajador del gobierno, el número de años de educación, estar ocupado como white collar y las horas por semana. Podemos ver esto por los coeficientes negativos asociados a estas variables que significan que cuando aumenta el valor de la variable (variable numérica) o cuando la variable es igual a 1 (categórica), la probabilidad de ganar menos de 50 mil disminuye.  

Las demás variables tienen un efecto positivo sobre la probabilidad de ganar poco. Las variables que representan el sexo femenino y razas diferentes a White tienen los coeficientes más grandes. Si están presentes estas variables (su valor sería igual a 1), aumenta la probabilidad de ganar poco. 




## Matriz de confusión  
  
**A continuación analiza la precisión del modelo, comparando la predicción del modelo contra el conjunto de prueba (testing_set). Asumiremos que la predicción del modelo es 1 (salario por debajo de 50k€) si la probabilidad del modelo de regresión logística es superior o igual a 0.5 y 0 de lo contrario. Analice la matriz de confusión y las medidas de sensibilidad y especificidad.**  
  
**Nota: Toma como categoría de interés que el salario esté por debajo de 50k€. Por tanto, Less50 igual a 1 será el caso positivo en la matriz de confusión y 0 el caso negativo.**    

Usamos ifelse para asignar los valores 0 y 1 según la probabilidad predicha por el modelo. 

```{r}
predictions <- ifelse(predict(model.reg, test.reg, type = 'response') < 0.5, 0, 1)

```


Guardamos la predicción en una columna de los datos de test



```{r}
test.reg$prediction <- predictions
```


Creamos la matriz de confusión usando table.  

El modelo predice correctamente 1885 casos de salario alto y 3137 casos de salario bajo. 


El porcentaje de clasificación correcta es del 92.5%.  
```{r echo=TRUE, message=FALSE, warning=FALSE}
conf.matr <- table(predictions, test.reg$Less50)

conf.matr

(conf.matr[1] + conf.matr[4])/(sum(colSums(conf.matr)))
```



Calculamos los verdaderos positivos y negativos, falsos positivos y negativos. Estos son los mismos valores que podemos ver en la matriz de confusión.   

Los verdaderos positivos/negativos son aquellas observaciones que son positivos/negativos según la predicción y también son positivos/negativos en realidad.

Los falsos positivos/negativos son las observaciones que son positivos/negativos en la realidad pero el modelo las ha predicho como lo opuesto (negativos/positivos)


```{r echo=TRUE, message=FALSE, warning=FALSE}
tp <- sum(test.reg$Less50==1 & test.reg$prediction == 1)
tn <- sum(test.reg$Less50==0 & test.reg$prediction == 0)
fp <- sum(test.reg$Less50==0 & test.reg$prediction == 1)
fn <- sum(test.reg$Less50==1 & test.reg$prediction == 0)

``` 


```{r echo=TRUE, message=FALSE, warning=FALSE}
cm <- data.frame(tp, tn, fp, fn)
cm
```

  

La sensibilidad es la proporcion de verdaderos positivos entre los positivos totales (verdaderos y falsos)

La especificidad es la proporción de verdaderos negativos entre los negativos totales (verdaderos y falsos)  

El modelo parece que predice casi igual de bien los positivos y los negativos.  


```{r echo=TRUE, message=FALSE, warning=FALSE}
sensitivity <- (tp) / (tp + fn) 
especif <- (tn) / (tn + fp)

sensitivity
especif
``` 




## Predicción  


**Utiliza el modelo anterior para realizar predicciones. Haga el cálculo de la predicción manualmente, y use la función predict para validar.**  

 * **¿Con qué probabilidad el salario de un individuo será menor a 50k€ para un hombre blanco de 20 años de edad, autónomo (self-employed), con 3 años de estudios, soltero, trabajando en el sector profesional, y ¿trabajando actualmente unas 25 horas semanales?**   


Guardamos los datos para usar la función predict.  

```{r echo=TRUE, message=FALSE, warning=FALSE}

newdata.lr = data.frame(age=20, workclass='Self-Employed', education_num=3, marital_status='Single', occupation='Professional', hours_per_week=25, gender="Male", race="White")
```  



Aquí creamos un vector que tiene las posibles opciones de la variable. Por el output del modelo hemos visto que el modelo genera variables dummies. Por ejemplo, si tomamos el género, que es 1 variable con dos niveles, el modelo la considera como 2 variables: una para masculino, otra para femenino, las dos son excluyentes mutuamente. Si el género es masculino, entonces su valor será 1 y el valor del género femenino será 0. Aplicamos esto para todas las variables presentes en la regresión y tenemos el vector. Multiplicamos el vector por los coeficientes del modelo.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
suma <- sum(c(1, 20, 0, 0, 1, 3, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 25) * model.reg$coefficients)

```


La probabilidad se calcula según la fófmula siguiente:  

```{r echo=TRUE, message=FALSE, warning=FALSE}
(1)/(1+exp(-suma))
```


Ahora hacemos la predicción y podemos comprobar que tenemos el mismo resultado.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
predict(model.reg, newdata.lr, type = 'response')

``` 

Hemos predicho con qué probabilidad una persona con los datos proporcionados en el enunciado va a tener un sueldo por debajo de 50 mil. La respuesta es con 99.8%


* **¿Con qué probabilidad el salario de un individuo será menor a 50k€ para un hombre negro de 60 años de edad, con trabajo gubernamental, con 15 años de estudios, casado, trabajando como ‘white-collar’, y ¿trabajando actualmente unas 35 horas semanales?**


Guardamos los datos para usar con predict.  

```{r echo=TRUE, message=FALSE, warning=FALSE}

newdata.lr1 = data.frame(age=60, workclass='Government', education_num=15, marital_status='Married', occupation='White-Collar', hours_per_week=35, gender="Male", race="Black")



``` 


De la misma forma que antes: intercept: 1, edada 60, Workclass government es la primera de la lista de workclass: 1 para este valor y 0 para todas las otras ocupaciones.. Así hasta completar los datos.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
suma1 <- sum(c(1, 60, 1, 0, 0, 15, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 35) * model.reg$coefficients)

```

Calculamos la probabilidad   

```{r echo=TRUE, message=FALSE, warning=FALSE}
(1)/(1+exp(-suma1))

```


Predecimos  y tenemos que con los datos proporcionados en este apartado la probabilidad que la persona gane menos de 50k es muy baja: de 0.44%  
```{r echo=TRUE, message=FALSE, warning=FALSE}
predict(model.reg, newdata.lr1, type = 'response')

```



# Análisis de la varianza (ANOVA) de un factor  
## Visualización  
  
**En este apartado, nos centraremos en analizar la existencia de diferencias significativas de income entre los diferentes grupos raciales. Tomaremos siempre un nivel de significación del 5%.**  
  
* **Haga un análisis visual de esta dependencia.**  
  
Visualizamos la variable "income" según la raza.    

Según los datos que tenemos, las personas de raza blanca tienen ingresos considerameblemente mayores que todas las demás razas y en especial que la raza other - otras razas, que tiene ingresos más bajos en el conjunto.  
  
  
Parece que los ingresos de personas de islas de asia pacífico y las personas negras tienen distribuciones de ingresos parecidas, las medianas muy parecidas  

Aunque las personas de raza blanca tienen por lo general ingresos más altos, el bigote bajo del plot que es Q1-1.5IQR para los blancos es tan bajo como para todas las otras razas, excepto "Other".  


```{r echo=TRUE, message=FALSE, warning=FALSE, fig.width=10, fig.height=6}

boxplot(adult$income~adult$race, col="red")
```  



## Modelo ANOVA  
  
**Completa los siguientes apartados:**  
  
### Formula el modelo  
  
**Explica el modelo que se plantea en el ANOVA.**    
Vamos a aplicar un modelo ANOVA de un factor que se use para detectar si dentro de un factor hay diferencias entre sus niveles de forma que estas diferencias contribuyen de explicar la variable objetivo "income". En este modelo vamos a usar el factor "race" con el ANOVA comprobaremos si los grupos que representan las razas son homogeneos dentro del grupo y los grupos son bastante diferentes entre ellos. En otras palabras buscamos ver si la variabilidad entre grupos es mayor que la variabilidad dentro de cada grupo.  

  
### Indica las hipótesis nula y alternativa  
  
**Escrivid las hipótesis nula y alternativa.**  

$H_0$: $\mu_{White}=\mu_{Black}=\mu_{Asian-Pac-Islander}=\mu_{Amer-Indian-Eskimo}=\mu_{Other}$  
  
$H_1$: $\mu_{i}\neq\mu_{j}$ para algún $i\neq j$, donde i,j son niveles de factor "race".  
  
### Estima la signifcación del factor grupo racial  
  
**Calculad la variabilidad explicada per la variable race sobre la variable income mediante la función anova().**  
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
model.anova <- lm(income~race, data=adult)
anva <- anova(model.anova)
anva
```  
  
$\eta^2$ es la medida de la asociación que se define como la proporción de la varianza de la variable objetivo(income) explicada por la variable predictora(race).  

La variable raza explica el 12.9% de la variabilidad de la variable "income".  
```{r echo=TRUE, message=FALSE, warning=FALSE}
ssa <- anva$`Sum Sq`[1]
sse <- anva$`Sum Sq`[2]

eta2 <- ssa/(ssa+sse)
eta2

```   

```{r echo=TRUE, message=FALSE, warning=FALSE}

``` 

 
  
### Estima los efectos de los niveles de factor  

La media del tratamiento se expresa como la media general más el efecto del tratamiento. Si el efecto es negativo, la media del tratamiento es menor que la media general. 

$\mu_i = \mu + \alpha_i $
  
De la fórmula podemos calcular el valor del efecto.  

En un diseño balanceado la suma de los efectos de los niveles de un factor sería igual a cero. En este caso los efectos de los niveles del factor raza se encuentran a continuación.   

El efecto que tiene la raza blanca sobre los ingresos es aumentarlos en una unidad con respecto a la media general. Todas las demás razas tienen el efecto de reducir los ingresos con respecto a su media. Ya hemos visto esto en los diagramas de cajas.  

En este caso debemos mencionar que las personas de raza blanca son la mayoria en estos datos, entonces influyen mucho en la media. Si tuvieramos un diseño balanceado, el efecto de la raza blanca tendría un valor positivo mucho más alto.  


  
```{r}
mu <- mean(adult$income)

med.white <- mean(adult$income[adult$race=='White'])
med.black <- mean(adult$income[adult$race=='Black'])
med.aspais <- mean(adult$income[adult$race=='Asian-Pac-Islander'])
med.amines <- mean(adult$income[adult$race=='Amer-Indian-Eskimo'])
med.other <- mean(adult$income[adult$race=='Other'])

alfa.white <- med.white - mu
alfa.black <- med.black - mu
alfa.aspais <- med.aspais - mu
alfa.amines <- med.amines - mu
alfa.other <- med.other - mu

alfa.white
alfa.black
alfa.aspais
alfa.amines
alfa.other
```



  
**Interpretad los resultados del modelo generado en el apartado anterior.**  
  
Sum Sq de la raza es SSA, la suma de cuadrados de los tratamientos. SSA indica las diferencias entre las medias de grupos.
Sum Sq de los residuos es SSE, la suma de cuadrados de error
Mean Sq de la raza es MSA, se calcula como SSA/(número de niveles - 1)
Mean Sq de los residuos es MSE, se calcula como SSE/(número de observaciones - número de niveles).
El valor F sería igual a 1 para $H_0$ cierta. Se calcula como MSA/MSE. Cuando MSA y MSE son similares, la variabilidad dentro de los grupos es similar a la variabilidad entre grupos y podemos decir que los grupos influyen poco en la variable "income".
  
El estadístico F es mucho mayor que 1 y Pr(>F) es menor que el nivel de significanzia, entonces podemos rechazar $H_0$ y considerar que factor "race" es significativo para explicar los ingresos.  
  


  
### Realiza los contrastes dos-a-dos  
  
**Para los contrastes dos-a-dos, podeis usar, por ejemplo, la función HSD.test() del paquete agricolae.**  
  
Hacemos el test HSD.test() que compara los distintos niveles de factor y devuelve resultados sobre lo mucho o poco que se parecen entre ellos, por parejas.  
En primer lugar muestra unas estastísticas sobre los niveles de factor y en el apartado "comparison" muestra los niveles de factor por pares y con un pvalue proporciona información sobre la igualidad de medias entre los niveles.  
  
En los resultados vemos que la raza blanca tienes valores de ingresos medios significativamente diferentes de las otras razas porque los valores de pvalue están por debajo del nivel de significancia de 0.05.  
  
Las parejas Amer-Indian-Eskimo - Asian-Pac-Islander y Asian-Pac-Islander - Black tienen pvalues por encima de 0.05, entonces no hay diferencias significativas entre las parejas.
```{r echo=TRUE, message=FALSE, warning=FALSE}
library(agricolae)

res.pair <- HSD.test(model.anova, "race", group = FALSE)
res.pair

``` 
  
Ahora podemos confirmar que el modelo situa a la raza negra y a la raza Asian-Pac-Islander en el grupo b y también la raza Asian-Pac-Islander junto con la raza Amer-Indian-Eskimo en grupo c. La raza Asian-Pac-Islander se encuentra en 2 grupos, los ingresos medios de esta raza son bastante similares a los ingresos de dos grupos, pero esto no signifia que los ingresos de la raza negra y la raza Amer-Indian-Eskimo son iguales. Estas dos razas están en grupos distintos.
```{r echo=TRUE, message=FALSE, warning=FALSE}
res.pair2 <- HSD.test(model.anova, "race", group = TRUE)
res.pair2$groups
``` 

  
### Adecuación del modelo  
  
**Mostrad la adecuación del modelo ANOVA en los dos siguientes sub-apartados.**  
  
#### Homocedasticidad de los residuos  
  
**El gráfico “Residuals vs Fitted” proporciona información sobre la homocedasticidad de los residuos. Mostrad e interpretad este gráfico.**    


Podemos ver que hay 5 grupos distintos, como hay 5 niveles del factor raza. Los valores predichos son los más bajos para la raza "Other" y más altos para la raza blanca. En la raza blanca hay mayor rango de residuos, esto significaría que para este nivel del factor hay mucha variabilidad, hay algo más de residuos por debajo de la línea roja (residuos negativos), entonces el valor predicho es más a menudo mayor que el real.  

Para las demás razas los residuos están más compactos junto a la línea roja.

La amplitud de la línea formada por los puntos indica la variabilidad de los ingresos para cada categoría. La raza blanca es la que tiene mayor variabilidad de ingresos y la raza Amer-Indian-Eskimo tiene la menor variabilidad. Todo esto indica que la varianza entre los grupos no es constante, hay heterocedasticidad.  
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
plot(model.anova, which = 1, col=adult$race,  legend = adult$race)

```
  
#### Normalidad de los residuos    
  
**Se puede comprovar el supuesto de normalidad de los residuos con los gráficos usuales. Aplicad también el test de Kruskal-Wallis e interpretad los resultados.**    

La línea formada por los residuos no se ajusta a la QQ line, esto indica que los residuos no siguen una distribución normal. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
plot(model.anova, which = 2)

```  
  
Aplicamos el test de Kruskal-Wallis. Ya que el pvalue es menor que el nivel de significancia 0.05, podemos concluir que hay diferencias significativas entre los grupos de tratamiento.  
```{r echo=TRUE, message=FALSE, warning=FALSE}

kruskal.test(income~race, data = adult)
``` 



# ANOVA multifactorial  
## Estudio visual de la interacción  


* **Calcula la tabla cruzada entre razas y empleos para saber cuántas observaciones hay por condición. ¿Se trata de un escenario balanceado? Valora los posibles inconvenientes de la modelización basada en anova en caso de un escenario no balanceado.**   


En primer lugar vemos los recuentos por raza y ocupación. En ocupación hay mayor número de personas Blue Collar y en razas la mayoría de personas son blancas.  

Llamamos un diseño balanceado aquel que tiene el mismo número de réplicas para cada tratamiento. En este dataset los datos que predominan son de la raza blanca para todos los niveles de ocupación. El siguiente nivel del factor raza con mayor número de observaciones es la raza negra.   


En un diseño disbalanceado el test pierde fuerza.
El test y el estadístico F es más sensible a la violación de la condición de la homocedasticidad. 
```{r echo=TRUE, message=FALSE, warning=FALSE}

colSums(table(adult$race, adult$occupation))
rowSums(table(adult$race, adult$occupation))

table(adult$race, as.factor(adult$occupation))






```  

 



* **Representa la interacción entre ambos factores y comenta los gráficos resultantes.**

El efecto principal de la ocupación "Blue-Collar" para las razas "Other" y "White" es aumentar los ingresos, para otras razas también dan ingresos altos, pero para razas que no son "Other" o "White" es la ocupación "White-Collar" que tiene el efecto de dar ingresos máximos. Esto es, hay interacción entre la ocupación blue collar y la raza.  

Los ingresos son parecidos para trabajadores profesionales y blue collar para razas que no son blancos ni otros.   

El efecto principal de la ocupación desconocida es dar los ingresos mínimos para todas las razas.  

El efecto principal de la raza blanca es dar ingresos más altos que para otras razas, sea cual sea la ocupación. Los ingresos que puede tener una persona blanca con ocupación más desventajosa son equiparables a los que puede tener una persona "Amer-Indian-Eskimo" de Blue Collar. 

El efecto principal de otras razas es dar el menor ingreso sea cual sea la ocupación.  

En general, podemos decir que hay interacción cuando las líneas mostradas no sean paralelas o se crucen. Así en la sección que representa Indios y eskimales frente a isleños de asia pacífico, el efecto principal del tratamiento de isleños es aumentar el nivel de ingresos y en el caso de las ocupaciones de ventas con otras existe interacción.   
```{r echo=TRUE, message=FALSE, warning=FALSE, fig.width=10, fig.height=6}
interaction.plot(adult$race, as.factor(adult$occupation), adult$income, col = 1:7,lty = 7, lwd=2.5)

``` 

Podemos mostrar los datos de otra forma. Aquí podemos ver claramente que el efecto de la raza blanca es dar los mayores ingresos para todas las ocupaciones, el efecto de otras razas es dar los peores ingresos.  

El efecto de la raza "Amer-Indian-Eskimo" es similar que el que tienen las razas "Black" y "Asian-Pac-Islander" para los dos primeros tipos de ocupación que se representan en el gráfico. Para las ocupaciones "Professional" y "Sales" el efecto principal de esta raza es dar menores ingresos. 

```{r echo=TRUE, message=FALSE, warning=FALSE, fig.width=10, fig.height=6}

interaction.plot(as.factor(adult$occupation), adult$race, adult$income,   col = 1:7,lty = 7, lwd=2.5)
```




# Conclusiones  


A lo largo de la práctica hemos hecho hemos un resumen de los conocimientos adquiridos durante la asginatura. Hemos usado los datos sobre los ingresos de adultos en EEUU.  

En el análisis visual con un boxplot de los ingresos de género masculino vs femenino podemos ver que casi todos los hombres cobra más que la mujer mediana. 

Por otra parte, el boxplot ingresos por razas confirma otra creencia, que las personas de raza blanca cobran más que todas las demás.   


```{r echo=FALSE}
boxplot(adult$income~adult$gender, main = "Income according to gender.", col="orange")

boxplot(adult$income~adult$race, main = "Income according to race.", col="orange", cex.axis=0.7)
```

Con otros diagramas de cajas vemos que los trabajadores gubernamentales, las personas casadas tienen mejores ingresos. 

En cuanto a las variables continuas, destacar que la mayoría de personas trabaja 40 horas y las que trabajan más horas no cobran más o no mucho más. Posiblemente serán personas que están empleados en varios trabajos precarios.  

El nivel de estudios tampoco es muy importante para los ingresos: a partir de un nivel de 8 años los ingresos máximos no mejoran mucho, los mínimos sí aumentan.  

**Contrastes**  

*Género*
Hemos querido contrastar si los hombres cobran más que las mujeres. El resultado del contraste que hemos hecho con un nivel de significancia del 5% es que los hombres sí cobran más. 


*Raza*  
En este caso también hemos podido rechazar la hipótesis nula. Con un nivel de confianza del 95% podemos afirmar que las personas de raza blanca cobran al menos 6.450k más que las personas de la raza negra. 

Estos resultados no son sorprendentes, confirman lo que ya intuimos y lo que muestran los diagramas de cajas.  


**Regresión**  

Ajustamos una regresión lineal para predecir los ingresos en función de la edad, la educación, horas trabajadas por semana, género, raza. El modelo muestra que las variables son significativas y que la raza Other y Asian-Pacific Islander reducen los ingresos. El modelo y las variables que hemos elegido para explicar los ingresos explican el 67% de la variabilidad de los ingresos. 

Las conclusiones de este modelo son que ser de **algunas razas de hecho penaliza los ingresos**. 

Por otra parte, las variables que **influyen positivamente y con coeficientes muy fuertes son la raza blanca y el género masculino.**  

Volvemos a confirmar lo que hemos visto hasta ahora: el hombre blanco cobra más.  


**Regresión logística**  

En esta ocasión queremos predecir una categoría: personas que cobran mucho contra las que cobran poco. Para ello usamos la edad, la clase laboral, años de educación, estado civil, ocupación, raza, género, horas trabajadas. Otra vez todas las variables son significativas, algunas de ellas **reducen la probabilidad de que ocurra el 1 (ganar menos de 50k)** y estas variables son: **trabajar en el gobierno, la edad, los años de estudios, tener ocupación white collar y las horas por semana trabajadas**. Es decir, no ser demasiado jóven aumenta la probabilidad de ganar más, también ocurre si uno trabaja para el gobierno (así para todas las variables mencionadas).  

Este modelo tiene un porcentaje de aciertos bastante bueno (92.5%), la sensibilidad y la especificidad también son de 92 y casi 93%


**ANOVA**   

En anova de un factor queremos trabajar otra vez el tema de los ingresos y la raza. Ya hemos visto en los ejercicios anteriores que la raza parece ser importante. Lo confirmaremos aquí. 

Los datos de la raza según el eta al cuadrado **explican el 13% de la variabilidad del modelo**.  

En primer lugar volvemos a ver el boxplot, da la impresión que la raza blanca y la raza Other están totalmente separadas de las demás y Isleño de Asia Pacífico y Negro tienen distribuciones parecidas. La raza American Indian Eskimo se parece a las últimas dos pero puede que caiga en otro grupo.   

Al realizar el anova vemos que sí **hay diferencias entre los grupos**, el valor del estadístico Pr(>F) permite rechazar la hipótesis nula del anova que sería que no hay diferencias. La afirmación es válida con un nivel de confianza del 95%.  

Como hay diferencias, los contrastes por parejas nos ayudarán a ver dónde están. Más abajo aparece que nuestra intuición se confirma, White, Other son grupos totalmente separados de los demás, Isleño de Asia Pacífico se parece tanto al American Indian Eskimo como al Black.  

**White es el grupo que más gana de media, other - el que menos.**


```{r echo=FALSE}
res.pair2 <- HSD.test(model.anova, "race", group = TRUE)
res.pair2$groups

```

En definitiva, con estos datos podemos decir que el factor que representa la raza tiene grupos diferenciados que son similares dentro y disimilares fuera.     


**Anova multifactorial**  

Aquí realmente no aplicamos el test, solamente vemos la interacción entre los tratamientos. Otra vez confirmamos que **las personas blancas ganan más que todas las demás**. Las líneas no se cruzan en muchos lugares, suelen ser paralelas o lo bastante, esto significa que por ejemplo las personas de white collar tienen consistentemente de los mayores ingresos que todas las otras ocupaciones. Sería así si no fuera por blue collar que para la raza negra parece tener un comportamiento diferente que en todas las demás razas. Si la línea siguiera la misma pendiente que las otras razas, las personas negras cobrarían más trabajando de blue collar que de white collar, pero no es así.  

En general en los datos hemos visto que en las razas y en ocupaciones en las instancias de Other las condiciones son las menos beneficiosas.  




```{r echo=FALSE}
interaction.plot(adult$race, as.factor(adult$occupation), adult$income, col = 1:7,lty = 7, lwd=2.5)

```


**Con la práctica hemos podido confirmar las concepciones que tenemos sobre el mundo: los hombres cobran más, los blancos cobran más. Por otra parte vemos que la raza negra no es la más perjudicada, así hay otra raza (Other) que tiene condiciones peores en todos los casos.**  


